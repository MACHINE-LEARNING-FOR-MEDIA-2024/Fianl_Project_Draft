{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project with Pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import helpers\n",
    "\n",
    "Run the following cells to import helper functions, files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- https://github.com/DM-GY-9103-2024F-H/9103-utils/releases/latest/download/lfw.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from data_utils import PCA, RandomForestClassifier, StandardScaler, SVC\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from data_utils import LFWUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "from random import choice\n",
    "\n",
    "from image_utils import open_image, make_image, edges\n",
    "from HW06_utils import HW06Utils\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from os import listdir, path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from data_utils import LFWUtils\n",
    "\n",
    "from image_utils import make_image, open_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from os import listdir, path\n",
    "\n",
    "from image_utils import make_image, open_image\n",
    "\n",
    "from HW12_utils import HW12Utils, FaceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "\n",
    "### Reading all the labeled files\n",
    "\n",
    "Let's first read all of the files in the `data/images/classification/train` directory.\n",
    "\n",
    "We are going to use the `Python` system function `listdir()` for listing files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare location of train files\n",
    "TRAIN_PATH = \"data/images/pokemon_train\"\n",
    "\n",
    "# List comprehension for getting all of the filenames that end in \"jpg\" inside the train directory\n",
    "train_files = [f for f in listdir(TRAIN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking our list\n",
    "\n",
    "Take a look at the `train_files` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# print the size of the train_files list here, along with some of its contents\n",
    "print(len(train_files))\n",
    "train_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the unlabeled files\n",
    "\n",
    "Repeat the above steps to get the names of all of the files inside the `data/images/classification/test` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Fill out the values for these two variables\n",
    "\n",
    "# Declare location of test files\n",
    "TEST_PATH = \"data/images/pokemon_test\"\n",
    "\n",
    "# Get all of the filenames that end in \"jpg\" inside the test directory\n",
    "test_files = [f for f in listdir(TEST_PATH) if f.endswith(\"png\")]\n",
    "\n",
    "# Print the number of files inside the list and some of its contents\n",
    "print(len(test_files))\n",
    "test_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through the files\n",
    "\n",
    "Iterate through all of the files in `train_files`, open them, and get the number of pixels for each image.\n",
    "\n",
    "In order to analyze, plot and process our data later, let's keep track of the number of pixels and the name of the file in a list with the following format:\n",
    "\n",
    "```py\n",
    "file_info = [\n",
    "  [value, filename],\n",
    "  [value, filename],\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "`file_info` is a list of lists, where each inner list has two members, `value`, which is some numeric info about the image, and `filename`, which is the name of the file.\n",
    "\n",
    "The `value` is the number of pixels in each image file.\n",
    "\n",
    "We'll use the `Python` function `path.join()` to get the full path of the files inside our `train_files` list.\n",
    "\n",
    "And then, just like in the previous homework, we can use the `plot_labels_vals()` function inside the `HW06Utils` class to plot the info we extract from our files.\n",
    "\n",
    "We just have to call the function with a list of `[value, filename]` elements, and a title for our graph.\n",
    "\n",
    "If the `filename` used contains information about the image label it will group values by those labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to keep info about image files\n",
    "length_info_train = []\n",
    "\n",
    "# iterate through all of the filenames inside the train files list\n",
    "for fname in train_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath = path.join(TRAIN_PATH, fname)\n",
    "\n",
    "  # open the file and read its pixels into an array\n",
    "  mimg = open_image(fpath)\n",
    "  mpxs = mimg.pixels\n",
    "\n",
    "  # get value of interest (number of pixels in image)\n",
    "  val = len(mpxs)\n",
    "\n",
    "  # store the info using the format specified above\n",
    "  length_info_train.append([ val, fname ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(length_info_train))\n",
    "\n",
    "# plot the (val, filename) pairs\n",
    "HW06Utils.plot_labels_vals(length_info_train, \"Train file pixel counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for `test` files\n",
    "\n",
    "Repeat the above process for the test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# list to keep info about image files\n",
    "length_info_test = []\n",
    "\n",
    "for fname_test in test_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath_test = path.join(TEST_PATH, fname_test)\n",
    "\n",
    "  # open the file and read its pixels into an array\n",
    "  mimg_test = open_image(fpath_test)\n",
    "  mpxs_test = mimg_test.pixels\n",
    "\n",
    "  # get value of interest (number of pixels in image)\n",
    "  val_test = len(mpxs_test)\n",
    "\n",
    "  # store the info using the format specified above\n",
    "  length_info_test.append([ val_test, fname_test ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(length_info_test))\n",
    "\n",
    "# plot the (val, filename) pairs\n",
    "HW06Utils.plot_labels_vals(length_info_test, \"Test file pixel counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at other(color) data\n",
    "\n",
    "```py\n",
    "pixel_ratio = HW06Utils.color_ratio(img, color, thold)\n",
    "```\n",
    "\n",
    "It takes an image, a color and a threshold value as inputs, and returns the ratio of detected pixels of that color relative to the total number of pixels in the image.\n",
    "\n",
    "We want to use relative pixel counts or ratios to avoid any kind of bias due to image sizes. If we used absolute count, small areas of purple pixels in large images might overshadow large areas of purple pixels in smaller images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to keep info about image files\n",
    "image_info_train = []\n",
    "\n",
    "# color to filter: Orchid\n",
    "keep_color = (186, 85, 211)\n",
    "\n",
    "# iterate through all of the filenames inside the train files list\n",
    "for fname in train_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath = path.join(TRAIN_PATH, fname)\n",
    "\n",
    "  # open the file and read its pixels into an array\n",
    "  mimg = open_image(fpath)\n",
    "\n",
    "  # get value of interest (purple pixel ratio)\n",
    "  val = HW06Utils.color_ratio(mimg, keep_color, 180)\n",
    "\n",
    "  # store the info using the format specified above\n",
    "  image_info_train.append([ val, fname ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(image_info_train))\n",
    "\n",
    "HW06Utils.plot_labels_vals(image_info_train, \"Train: purple ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model\n",
    "\n",
    "Let's use the info in the graph and create a function that outputs the image label based on its purple pixel amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes an image and returns a label\n",
    "def purple_ratio_classifier(img):\n",
    "  keep_color = (186, 85, 211)\n",
    "  purple_ratio = HW06Utils.color_ratio(img, keep_color, 180)\n",
    "  if purple_ratio > 0.6:\n",
    "    return \"generated\"\n",
    "  else:\n",
    "    return \"original\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random classifier\n",
    "\n",
    "We're also gonna create a random classifier to use as a baseline for comparisons later.\n",
    "\n",
    "The random classifier just guesses a label randomly. Our model should do better than random guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random classifier to use for comparisons\n",
    "def random_classifier(_):\n",
    "  # the choice() function selects a random element from a list\n",
    "  return choice([\"generated\",\"original\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run classification on `train` data\n",
    "\n",
    "Let's iterate through all the train files again, and this time instead of saving the purple ratio value and the filename in the list, we'll save our calculated label and the filename.\n",
    "\n",
    "```py\n",
    "purple_ratio_predictions = [\n",
    "  [label, filename],\n",
    "  [label, filename],\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "We'll also keep track of classifications made by the `random_classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to keep info about predictions\n",
    "purple_ratio_predictions_train = []\n",
    "\n",
    "# list to keep info about random predictions\n",
    "random_predictions_train = []\n",
    "\n",
    "# iterate through all of the filenames inside the train files list\n",
    "for fname in train_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath = path.join(TRAIN_PATH, fname)\n",
    "\n",
    "  # open the image from the file\n",
    "  mimg = open_image(fpath)\n",
    "\n",
    "  # get prediction using model defined above\n",
    "  prediction = purple_ratio_classifier(mimg)\n",
    "\n",
    "  # get prediction using random classifier defined above\n",
    "  random_prediction = random_classifier(mimg)\n",
    "\n",
    "  # store the prediction and filename\n",
    "  purple_ratio_predictions_train.append([ prediction, fname ])\n",
    "\n",
    "  # store the random prediction and filename\n",
    "  random_predictions_train.append([ random_prediction, fname ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(purple_ratio_predictions_train))\n",
    "\n",
    "# look at first couple of predictions just to check that our format is correct\n",
    "print(purple_ratio_predictions_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# list to keep info about predictions\n",
    "purple_ratio_predictions_test = []\n",
    "\n",
    "for fname in test_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath = path.join(TEST_PATH, fname)\n",
    "\n",
    "  # open the image from the file\n",
    "  mimg = open_image(fpath)\n",
    "\n",
    "  # get prediction using model defined above\n",
    "  prediction = purple_ratio_classifier(mimg)\n",
    "\n",
    "  # store the prediction and filename\n",
    "  purple_ratio_predictions_test.append([ prediction, fname ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(purple_ratio_predictions_test))\n",
    "\n",
    "# look at first couple of predictions just to check that our format is correct\n",
    "print(purple_ratio_predictions_test[:3])\n",
    "\n",
    "#print(\"Purple Classifier\", HW06Utils.classification_accuracy(purple_ratio_predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (transparent origin images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to add lable\n",
    "def add_label(fname):\n",
    "    # Initialize the label\n",
    "    if 'gen' in fname:  # Check if 'gen' is in the filename\n",
    "        label = 1  # Assign 1 if 'gen' is found\n",
    "    else:\n",
    "        label = 0  # Assign 0 otherwise\n",
    "    return label  # Return the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def classification_accuracy(train_files, train_predictions):\n",
    "\n",
    "    # Ensure train_predictions is a DataFrame with exactly one column\n",
    "    if not isinstance(train_predictions, pd.DataFrame) or train_predictions.shape[1] != 1:\n",
    "        raise ValueError(\"train_predictions must be a DataFrame with a single column.\")\n",
    "    \n",
    "    # Extract predictions as a flat list/array\n",
    "    predictions = train_predictions.iloc[:, 0].tolist()\n",
    "\n",
    "    # Check if train_files and predictions have the same length\n",
    "    if len(train_files) != len(predictions):\n",
    "        raise ValueError(\"The length of train_files and train_predictions must match.\")\n",
    "\n",
    "    # Generate true labels from the filenames\n",
    "    true_labels = [1 if 'gen' in fname else 0 for fname in train_files]\n",
    "\n",
    "    # Compare predictions with true labels\n",
    "    correct_predictions = sum([pred == true for pred, true in zip(predictions, true_labels)])\n",
    "\n",
    "    # Calculate accuracy as a percentage\n",
    "    accuracy = (correct_predictions / len(train_files)) * 100\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group every 4 elements into sublists within the array\n",
    "def group_pixels(pixel_array, group_size=4):\n",
    "    grouped_pixels = np.array(pixel_array).reshape(-1, group_size)\n",
    "    return grouped_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split for dataframe\n",
    "def train_test_split(data, test_ratio=0.2, random_seed=None):\n",
    "\n",
    "    # Set the random seed for reproducibility (optional)\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Convert to a NumPy array for easier manipulation if it's a list\n",
    "    if isinstance(data, list):\n",
    "        data = np.array(data)\n",
    "\n",
    "    # Shuffle the indices of the data\n",
    "    indices = np.arange(len(data))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Compute the split point\n",
    "    split_point = int(len(data) * (1 - test_ratio))\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_indices = indices[:split_point]\n",
    "    test_indices = indices[split_point:]\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):  # For DataFrame input\n",
    "        train_data = data.iloc[train_indices]\n",
    "        test_data = data.iloc[test_indices]\n",
    "    else:  # For lists or NumPy arrays\n",
    "        train_data = data[train_indices]\n",
    "        test_data = data[test_indices]\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split_combined(data_combined, test_size=0.2):\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data_combined)\n",
    "    \n",
    "    # Calculate the split index\n",
    "    split_index = int(len(data_combined) * (1 - test_size))\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_data = data_combined[:split_index]\n",
    "    test_data = data_combined[split_index:]\n",
    "    \n",
    "    # Convert into dictionaries\n",
    "    train = {'pixels': [], 'labels': [], 'file_names': []}\n",
    "    test = {'pixels': [], 'labels': [], 'file_names': []}\n",
    "    \n",
    "    # Populate the train and test dictionaries\n",
    "    for pixels, label, file_name in train_data:\n",
    "        train['pixels'].append(pixels)\n",
    "        train['labels'].append(label)\n",
    "        train['file_names'].append(file_name)\n",
    "    \n",
    "    for pixels, label, file_name in test_data:\n",
    "        test['pixels'].append(pixels)\n",
    "        test['labels'].append(label)\n",
    "        test['file_names'].append(file_name)\n",
    "    \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template for black and white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = add_label(fname)\n",
    "  img = open_image(path.join(\"./data/images/pokemon_train\", fname))\n",
    "  pixel_data.append(img.pixels)\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = add_label(fname)\n",
    "  img = open_image(path.join(\"./data/images/pokemon_train\", fname))\n",
    " # Convert the pixel data to a NumPy array\n",
    "  pixel_array = np.array(img.pixels)\n",
    "    \n",
    "    # Flatten the NumPy array\n",
    "  flattened_pixels = pixel_array.flatten()\n",
    "    \n",
    "  pixel_data.append(flattened_pixels)\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Color Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group the pixel data for display\n",
    "image_0 = group_pixels(pixel_data[0], group_size=4)\n",
    "image_10 = group_pixels(pixel_data[10], group_size=4)\n",
    "\n",
    "# Display the grouped pixel data\n",
    "display(make_image(image_0, width=120))\n",
    "display(make_image(image_10, width=120))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Pixels into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(pixel_data)\n",
    "train_df[\"label\"] = label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixel_data = []\n",
    "\n",
    "# Flatten pixel data for each image\n",
    "for fname in test_files:\n",
    "    img = open_image(path.join(\"./data/images/pokemon_test\", fname))\n",
    "    # Flatten the image pixels into a 1D array\n",
    "    flattened_pixels = np.array(img.pixels).flatten()\n",
    "    test_pixel_data.append(flattened_pixels)\n",
    "\n",
    "# Load into DataFrame\n",
    "test_df = pd.DataFrame(test_pixel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split input and output features\n",
    "NUM_FEATURES = 5\n",
    "chosen_columns = train_df.columns[:NUM_FEATURES]\n",
    "train_features = train_df[chosen_columns]\n",
    "\n",
    "out_features = train_df[\"label\"]\n",
    "\n",
    "# also separate test dataset features\n",
    "test_features = test_df[chosen_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a brand new classifier\n",
    "image_model = RandomForestClassifier()\n",
    "# TODO: fit the model\n",
    "image_model.fit(train_features, out_features)\n",
    "# TODO: run predictions\n",
    "train_predictions = image_model.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_accuracy(train_files, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run predictions on test data\n",
    "test_predictions = image_model.predict(test_features)\n",
    "# TODO: measure classification accuracy\n",
    "classification_accuracy(test_files, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA from HW10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_GEN_PATH = \"data/images/pokemon_generated\"\n",
    "\n",
    "# Get all of the filenames that end in \"jpg\" inside the test directory\n",
    "train_gen_files = [f for f in listdir(TRAIN_GEN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the data\n",
    "pixel_data = []\n",
    "label_data = []\n",
    "file_names = []\n",
    "\n",
    "for fname in train_gen_files:\n",
    "    # Get the label for the image\n",
    "    label = add_label(fname)\n",
    "    \n",
    "    # Load the image\n",
    "    img = open_image(path.join(\"./data/images/pokemon_generated\", fname))\n",
    "    \n",
    "    # Convert the pixel data to a NumPy array and flatten it\n",
    "    pixel_array = np.array(img.pixels).flatten()\n",
    "    \n",
    "    # Append the data to the respective lists\n",
    "    pixel_data.append(pixel_array.tolist())  # Convert flattened NumPy array to list\n",
    "    label_data.append(label)\n",
    "    file_names.append(fname)\n",
    "\n",
    "# Create the DataFrame with three columns\n",
    "\n",
    "train_gen_df = pd.DataFrame({\n",
    "    \"pixels\": pixel_data,\n",
    "    \"label\": label_data,\n",
    "    \"fname\": file_names\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(train_gen_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pixel_data, label_data, and file_names into a single list\n",
    "train_gen = list(zip(pixel_data, label_data, file_names))\n",
    "\n",
    "# Example: Display the first combined item\n",
    "print(train_gen[0])  # Output: (pixels_list, label, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split_combined(train_gen,0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pca = PCA(n_components=8)\n",
    "train_df = face_pca.fit_transform(train[\"pixels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"explained variance:\", face_pca.explained_variance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this label to your label to see how\n",
    "#       your images are being encoded\n",
    "awesome_label = \"1\"\n",
    "\n",
    "\n",
    "# this filters the DataFrame by our label\n",
    "awesome_df = train_df\n",
    "\n",
    "# reconstruct all images\n",
    "pca_pixels = face_pca.inverse_transform(awesome_df)\n",
    "\n",
    "# associate the original indexes with the reconstructed pca pixels\n",
    "idx_pca = zip(awesome_df.index, pca_pixels.values)\n",
    "\n",
    "# iterate through indexes and pca pixels\n",
    "for img_idx, img_pca in list(idx_pca)[:5]:\n",
    "  print(\"label:\", awesome_label,\n",
    "        \"\\nfrom:\", train[\"file_names\"][img_idx])\n",
    "  # Group the pixel data for display\n",
    "  image_0 = group_pixels(train[\"pixels\"][img_idx], group_size=4)\n",
    "  image_10 = group_pixels(img_pca, group_size=4)\n",
    "\n",
    "# Display the grouped pixel data\n",
    "  display(make_image(image_0, width=120))\n",
    "  display(make_image(image_10, width=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ORI_PATH = \"data/images/pokemon_origin\"\n",
    "\n",
    "# Get all of the filenames that end in \"jpg\" inside the test directory\n",
    "train_ori_files = [f for f in listdir(TRAIN_ORI_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the data\n",
    "pixel_data = []\n",
    "label_data = []\n",
    "file_names = []\n",
    "\n",
    "for fname in train_ori_files:\n",
    "    # Get the label for the image\n",
    "    label = add_label(fname)\n",
    "    \n",
    "    # Load the image\n",
    "    img = open_image(path.join(\"./data/images/pokemon_origin\", fname))\n",
    "    \n",
    "    # Convert the pixel data to a NumPy array and flatten it\n",
    "    pixel_array = np.array(img.pixels).flatten()\n",
    "    \n",
    "    # Append the data to the respective lists\n",
    "    pixel_data.append(pixel_array.tolist())  # Convert flattened NumPy array to list\n",
    "    label_data.append(label)\n",
    "    file_names.append(fname)\n",
    "\n",
    "# Create the DataFrame with three columns\n",
    "\n",
    "train_ori_df = pd.DataFrame({\n",
    "    \"pixels\": pixel_data,\n",
    "    \"label\": label_data,\n",
    "    \"fname\": file_names\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(train_ori_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pixel_data, label_data, and file_names into a single list\n",
    "train_ori = list(zip(pixel_data, label_data, file_names))\n",
    "\n",
    "# Example: Display the first combined item\n",
    "print(train_ori[0])  # Output: (pixels_list, label, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split_combined(train_ori,0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pca = PCA(n_components=8)\n",
    "train_df = face_pca.fit_transform(train[\"pixels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"explained variance:\", face_pca.explained_variance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this label to your label to see how\n",
    "#       your images are being encoded\n",
    "awesome_label = \"0\"\n",
    "\n",
    "\n",
    "# this filters the DataFrame by our label\n",
    "awesome_df = train_df\n",
    "\n",
    "# reconstruct all images\n",
    "pca_pixels = face_pca.inverse_transform(awesome_df)\n",
    "\n",
    "# associate the original indexes with the reconstructed pca pixels\n",
    "idx_pca = zip(awesome_df.index, pca_pixels.values)\n",
    "\n",
    "# iterate through indexes and pca pixels\n",
    "for img_idx, img_pca in list(idx_pca)[:5]:\n",
    "  print(\"label:\", awesome_label,\n",
    "        \"\\nfrom:\", train[\"file_names\"][img_idx])\n",
    "  # Group the pixel data for display\n",
    "  image_0 = group_pixels(train[\"pixels\"][img_idx], group_size=4)\n",
    "  image_10 = group_pixels(img_pca, group_size=4)\n",
    "\n",
    "# Display the grouped pixel data\n",
    "  display(make_image(image_0, width=120))\n",
    "  display(make_image(image_10, width=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first attempted to manually classify the generated images and the original images based on the use of the purple pixel color and the result works really well. Based on this observation, I decided to further test the performance of a pre-built model, such as a Random Forest classifier, to see how it performs. One possible reason why the Random Forest classifier worked so well is that the original images are PNG files without a background, whereas the generated images include a background.\n",
    "\n",
    "Another reason could be the differences in how the color purple is used in the generated and original images, as indicated by a subsequent PCA analysis on both sets of images. For the PCA on the generated images, those with colors closer to purple tend to produce blurrier results, revealing additional layers with purple tones in the background. In contrast, for images like Pikachu that contain fewer red or purple tones, the results appear clearer compared to those with more red or purple tones.\n",
    "\n",
    "For the original images, Pok√©mon primarily constructed with red tones remain clear even after applying PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification with Background for Both Generated and Original Pokemon Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Show Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare location of train files\n",
    "TRAIN_PATH = \"data/images/pokemon_train_white\"\n",
    "\n",
    "# List comprehension for getting all of the filenames that end in \"png\" inside the train directory\n",
    "train_files = [f for f in listdir(TRAIN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = add_label(fname)\n",
    "  img = open_image(path.join(\"./data/images/pokemon_train_white\", fname))\n",
    " # Convert the pixel data to a NumPy array\n",
    "  pixel_array = np.array(img.pixels)\n",
    "    \n",
    "    # Flatten the NumPy array\n",
    "  flattened_pixels = pixel_array.flatten()\n",
    "    \n",
    "  pixel_data.append(flattened_pixels)\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group the pixel data for display\n",
    "image_0 = group_pixels(pixel_data[0], group_size=4)\n",
    "image_10 = group_pixels(pixel_data[10], group_size=4)\n",
    "\n",
    "# Display the grouped pixel data\n",
    "display(make_image(image_0, width=120))\n",
    "display(make_image(image_10, width=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Pixels into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(pixel_data)\n",
    "train_df[\"label\"] = label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare location of test files\n",
    "TRAIN_PATH = \"data/images/pokemon_test_white\"\n",
    "\n",
    "# List comprehension for getting all of the filenames that end in \"png\" inside the train directory\n",
    "test_files = [f for f in listdir(TRAIN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixel_data = []\n",
    "\n",
    "# Flatten pixel data for each image\n",
    "for fname in test_files:\n",
    "    img = open_image(path.join(\"./data/images/pokemon_test_white\", fname))\n",
    "    # Flatten the image pixels into a 1D array\n",
    "    flattened_pixels = np.array(img.pixels).flatten()\n",
    "    test_pixel_data.append(flattened_pixels)\n",
    "\n",
    "# Load into DataFrame\n",
    "test_df = pd.DataFrame(test_pixel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split input and output features\n",
    "NUM_FEATURES = 5\n",
    "chosen_columns = train_df.columns[:NUM_FEATURES]\n",
    "train_features = train_df[chosen_columns]\n",
    "\n",
    "out_features = train_df[\"label\"]\n",
    "\n",
    "# also separate test dataset features\n",
    "test_features = test_df[chosen_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a brand new classifier\n",
    "image_model = RandomForestClassifier()\n",
    "# TODO: fit the model\n",
    "image_model.fit(train_features, out_features)\n",
    "# TODO: run predictions\n",
    "train_predictions = image_model.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_accuracy(train_files, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run predictions on test data\n",
    "test_predictions = image_model.predict(test_features)\n",
    "# TODO: measure classification accuracy\n",
    "classification_accuracy(test_files, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still works well when the original image change from the transparent background into the white one as the generated files. Thus, I do not think the background is the reason that the classifier works so well. In contrast, according to the result of pca and the manual classifier I remain to the assumption that this is because the original images and the generated images use the color purple differently. The following session, I would use HW12 as a template to try the tensor to see if that works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the generated and origin folders ther to get a new folder (Only use once to create the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Paths to the original folders and the new folder\n",
    "# folder_a = \"data/images/pokemon_generated\"\n",
    "# folder_b =  \"data/images/pokemon_origin\"\n",
    "# new_folder =\"data/images/pokemon_origin_generate\"\n",
    "\n",
    "# # Create the new folder if it does not exist\n",
    "\n",
    "# if not os.path.exists(new_folder):\n",
    "#     os.makedirs(new_folder)\n",
    "\n",
    "# # Function to copy files from a folder to the new folder\n",
    "# def copy_files_to_new_folder(source_folder, destination_folder):\n",
    "#     for filename in os.listdir(source_folder):\n",
    "#         # Full path of the current file\n",
    "#         source_file = os.path.join(source_folder, filename)\n",
    "#         destination_file = os.path.join(destination_folder, filename)\n",
    "        \n",
    "#         # Check if it's a file and not a subfolder\n",
    "#         if os.path.isfile(source_file):\n",
    "#             # If the file already exists, you can decide how to handle it (skip, rename, etc.)\n",
    "#             if not os.path.exists(destination_file):\n",
    "#                 shutil.copy(source_file, destination_folder)\n",
    "#             else:\n",
    "#                 # Optional: rename file to avoid overwriting\n",
    "#                 base, extension = os.path.splitext(filename)\n",
    "#                 new_filename = base + \"_copy\" + extension\n",
    "#                 destination_file = os.path.join(destination_folder, new_filename)\n",
    "#                 shutil.copy(source_file, destination_file)\n",
    "\n",
    "# # Copy files from Folder A and Folder B to the new folder\n",
    "# copy_files_to_new_folder(folder_a, new_folder)\n",
    "# copy_files_to_new_folder(folder_b, new_folder)\n",
    "\n",
    "# print(\"Files copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pixel Dataframe with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NN_PATH=\"data/images/pokemon_origin_generate\"\n",
    "\n",
    "# Get all of the filenames that end in \"jpg\" inside the test directory\n",
    "train_ori_files = [f for f in listdir(TRAIN_NN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              pixels  label            fname\n",
      "0  [191, 191, 191, 255, 191, 191, 191, 255, 191, ...      1     new1_gen.png\n",
      "1  [173, 173, 173, 255, 172, 172, 172, 255, 171, ...      1  yanmega_gen.png\n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0        zorua.png\n",
      "3  [214, 214, 214, 255, 213, 213, 213, 255, 213, ...      1     new2_gen.png\n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0        yanma.png\n"
     ]
    }
   ],
   "source": [
    "# Lists to store the data\n",
    "pixel_data = []\n",
    "label_data = []\n",
    "file_names = []\n",
    "\n",
    "for fname in train_ori_files:\n",
    "    # Get the label for the image\n",
    "    label = add_label(fname)\n",
    "    \n",
    "    # Load the image\n",
    "    img = open_image(path.join(\"./data/images/pokemon_origin_generate\",fname))\n",
    "    \n",
    "    # Convert the pixel data to a NumPy array and flatten it\n",
    "    pixel_array = np.array(img.pixels).flatten()\n",
    "    \n",
    "    # Append the data to the respective lists\n",
    "    pixel_data.append(pixel_array.tolist())  # Convert flattened NumPy array to list\n",
    "    label_data.append(label)\n",
    "    file_names.append(fname)\n",
    "\n",
    "# Create the DataFrame with three columns\n",
    "\n",
    "train_ori_df = pd.DataFrame({\n",
    "    \"pixels\": pixel_data,\n",
    "    \"label\": label_data,\n",
    "    \"fname\": file_names\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(train_ori_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and into Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pixel_data, label_data, and file_names into a single list\n",
    "train_gen = list(zip(pixel_data, label_data, file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split_combined(train_gen,0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train = Tensor(train[\"pixels\"])\n",
    "y_train = Tensor(train[\"labels\"]).long()\n",
    "\n",
    "x_test = Tensor(test[\"pixels\"])\n",
    "y_test = Tensor(test[\"labels\"]).long()\n",
    "\n",
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(FaceDataset(x_train, y_train), batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(FaceDataset(x_test, y_test), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Modle and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the model, optimizer and loss function objects\n",
    "model = nn.Linear(x_train.shape[1], len(y_train.unique()))\n",
    "\n",
    "learning_rate = 1e-8\n",
    "optim = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 loss: 0.0671\n",
      "Epoch: 7 loss: 3.3420\n",
      "Epoch: 11 loss: 4.1531\n",
      "Epoch: 15 loss: 2.3872\n",
      "Epoch: 19 loss: 0.7270\n",
      "Epoch: 23 loss: 0.0312\n",
      "Epoch: 27 loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# TODO: iterate epochs\n",
    "for e in range(28):\n",
    "  # TODO: iterate batches\n",
    "  for imgs, labels in train_dataloader:\n",
    "    # TODO: predict\n",
    "    labels_pred = model(imgs)\n",
    "    # TODO: measure loss\n",
    "    loss = loss_fn(labels_pred, labels)\n",
    "    # TODO: compute gradient and step optimizer\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    # TODO: show progress\n",
    "  if e % 4 == 3:\n",
    "    print(f\"Epoch: {e} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(model, dataloader):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    data_labels = []\n",
    "    pred_labels = []\n",
    "    for imgs, labels in dataloader:\n",
    "      labels_pred = model(imgs).argmax(dim=1)\n",
    "      data_labels += [l.item() for l in labels]\n",
    "      pred_labels += [l.item() for l in labels_pred]\n",
    "    return data_labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_predictions = get_labels(model, train_dataloader)\n",
    "test_labels, test_predictions = get_labels(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_error(train_labels,train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09999999999999998"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_error(test_labels,test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NN also works really well. I assume this is because of the size of data. However, the classification error for the train and the test are almost the same, which is really interesting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
