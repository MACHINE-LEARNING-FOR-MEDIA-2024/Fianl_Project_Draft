{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW06\n",
    "\n",
    "Some exercises with images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import helpers\n",
    "\n",
    "Run the following 2 cells to import helper functions, files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- https://github.com/DM-GY-9103-2024F-H/9103-utils/releases/latest/download/lfw.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from data_utils import PCA, RandomForestClassifier, StandardScaler, SVC\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from data_utils import LFWUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "from random import choice\n",
    "\n",
    "from image_utils import open_image, make_image, edges\n",
    "from HW06_utils import HW06Utils\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from os import listdir, path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from data_utils import LFWUtils\n",
    "\n",
    "from image_utils import make_image, open_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "\n",
    "### 01A. Reading all the labeled files\n",
    "\n",
    "Let's first read all of the files in the `data/images/classification/train` directory.\n",
    "\n",
    "We are going to use the `Python` system function `listdir()` for listing files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare location of train files\n",
    "TRAIN_PATH = \"data/images/pokemon_train\"\n",
    "\n",
    "# List comprehension for getting all of the filenames that end in \"jpg\" inside the train directory\n",
    "train_files = [f for f in listdir(TRAIN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking our list\n",
    "\n",
    "Take a look at the `train_files` list.\n",
    "\n",
    "How many files are there?\n",
    "\n",
    "How are the file names formatted ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# print the size of the train_files list here, along with some of its contents\n",
    "print(len(train_files))\n",
    "train_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01B. Reading the unlabeled files\n",
    "\n",
    "Repeat the above steps to get the names of all of the files inside the `data/images/classification/test` directory.\n",
    "\n",
    "How many files are there?\n",
    "\n",
    "How are the files named?\n",
    "\n",
    "Print the number of files in the directory and their names below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Fill out the values for these two variables\n",
    "\n",
    "# Declare location of test files\n",
    "TEST_PATH = \"data/images/pokemon_test\"\n",
    "\n",
    "# Get all of the filenames that end in \"jpg\" inside the test directory\n",
    "test_files = [f for f in listdir(TEST_PATH) if f.endswith(\"png\")]\n",
    "\n",
    "# Print the number of files inside the list and some of its contents\n",
    "print(len(test_files))\n",
    "test_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02A. Iterating through the files\n",
    "\n",
    "Let's iterate through all of the files in `train_files`, open them, and get the number of pixels for each image.\n",
    "\n",
    "In order to analyze, plot and process our data later, let's keep track of the number of pixels and the name of the file in a list with the following format:\n",
    "\n",
    "```py\n",
    "file_info = [\n",
    "  [value, filename],\n",
    "  [value, filename],\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "This is exactly like how we organized data in the last homework assignment: `file_info` is a list of lists, where each inner list has two members, `value`, which is some numeric info about the image, and `filename`, which is the name of the file.\n",
    "\n",
    "For now, the `value` we are interested in extracting is the number of pixels in each image file.\n",
    "\n",
    "We'll use the `Python` function `path.join()` to get the full path of the files inside our `train_files` list.\n",
    "\n",
    "And then, just like in the previous homework, we can use the `plot_labels_vals()` function inside the `HW06Utils` class to plot the info we extract from our files.\n",
    "\n",
    "We just have to call the function with a list of `[value, filename]` elements, and a title for our graph.\n",
    "\n",
    "If the `filename` used contains information about the image label it will group values by those labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to keep info about image files\n",
    "length_info_train = []\n",
    "\n",
    "# iterate through all of the filenames inside the train files list\n",
    "for fname in train_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath = path.join(TRAIN_PATH, fname)\n",
    "\n",
    "  # open the file and read its pixels into an array\n",
    "  mimg = open_image(fpath)\n",
    "  mpxs = mimg.pixels\n",
    "\n",
    "  # get value of interest (number of pixels in image)\n",
    "  val = len(mpxs)\n",
    "\n",
    "  # store the info using the format specified above\n",
    "  length_info_train.append([ val, fname ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(length_info_train))\n",
    "\n",
    "# plot the (val, filename) pairs\n",
    "HW06Utils.plot_labels_vals(length_info_train, \"Train file pixel counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤”\n",
    "\n",
    "The values on the x-axis are the number of pixels in each file.\n",
    "\n",
    "We can see that the images all have different sizes, but they're all around $50000$ pixels, and it doesn't look like pixel count is a feature we could use to classify our images.\n",
    "\n",
    "But, let's make sure there are no patterns.\n",
    "\n",
    "### 02B. Repeat for `test` files\n",
    "\n",
    "Repeat the above process for the test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# list to keep info about image files\n",
    "length_info_test = []\n",
    "\n",
    "for fname_test in test_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath_test = path.join(TEST_PATH, fname_test)\n",
    "\n",
    "  # open the file and read its pixels into an array\n",
    "  mimg_test = open_image(fpath_test)\n",
    "  mpxs_test = mimg_test.pixels\n",
    "\n",
    "  # get value of interest (number of pixels in image)\n",
    "  val_test = len(mpxs_test)\n",
    "\n",
    "  # store the info using the format specified above\n",
    "  length_info_test.append([ val_test, fname_test ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(length_info_test))\n",
    "\n",
    "# plot the (val, filename) pairs\n",
    "HW06Utils.plot_labels_vals(length_info_test, \"Test file pixel counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are some image sizes that are more common, but it doesn't look like pixel count will tell us anything about the content of the image.\n",
    "\n",
    "Either way, it's always a good idea to plot any and all information about our data because sometimes we get lucky and find some pattern that is easy to extract and use.\n",
    "\n",
    "### 03. Looking at other data\n",
    "\n",
    "Let's repeat the process of extracting info from our files, but this time let's look at the image's color information.\n",
    "\n",
    "We saw many ways of counting pixel colors in the [WK06 notebook](https://github.com/DM-GY-9103-2024F-H/WK06): channel histograms, channel separation, channel average value, filtering etc. We could try out a few of these different techniques, but filtering and counting might be the easiest method for extracting info about colors that are in multiple channels.\n",
    "\n",
    "Just like we extracted the yellow flowers from the hedgehog image, let's start by filtering and counting the purple pixels. If an image has purple pixels, it's probably a `florist` picture. There's even an [html color](https://www.w3schools.com/colors/colors_names.asp) called [Orchid](https://www.w3schools.com/colors/color_tryit.asp?color=MediumOrchid) that we can try.\n",
    "\n",
    "The `color_ratio()` function from our [WK06 notebook](https://github.com/DM-GY-9103-2024F-H/WK06) is available inside the `HW06Utils` class, and we can just use it here by calling:\n",
    "\n",
    "```py\n",
    "pixel_ratio = HW06Utils.color_ratio(img, color, thold)\n",
    "```\n",
    "\n",
    "It takes an image, a color and a threshold value as inputs, and returns the ratio of detected pixels of that color relative to the total number of pixels in the image.\n",
    "\n",
    "We want to use relative pixel counts or ratios to avoid any kind of bias due to image sizes. If we used absolute count, small areas of purple pixels in large images might overshadow large areas of purple pixels in smaller images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to keep info about image files\n",
    "image_info_train = []\n",
    "\n",
    "# color to filter: Orchid\n",
    "keep_color = (186, 85, 211)\n",
    "\n",
    "# iterate through all of the filenames inside the train files list\n",
    "for fname in train_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath = path.join(TRAIN_PATH, fname)\n",
    "\n",
    "  # open the file and read its pixels into an array\n",
    "  mimg = open_image(fpath)\n",
    "\n",
    "  # get value of interest (purple pixel ratio)\n",
    "  val = HW06Utils.color_ratio(mimg, keep_color, 180)\n",
    "\n",
    "  # store the info using the format specified above\n",
    "  image_info_train.append([ val, fname ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(image_info_train))\n",
    "\n",
    "HW06Utils.plot_labels_vals(image_info_train, \"Train: purple ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤¨\n",
    "\n",
    "There's something of a pattern here.\n",
    "\n",
    "As expected, the `florist` images tend to have more `purple` than the other images, and surprisingly, `tree` images seem to have more purple than the `forest` images.\n",
    "\n",
    "Let's build a model for classifying our images based on purple pixel ratio.\n",
    "\n",
    "### 04. Create a model\n",
    "\n",
    "Let's use the info in the graph and create a function that outputs the image label based on its purple pixel amount.\n",
    "\n",
    "If the purple ratio of an image is greater than $0.8$ we'll say it's a `florist` image, if it's between $0.4$ and $0.8$ we'll label it `tree`, otherwise it's a `forest`.\n",
    "\n",
    "It won't be perfect, but we can check how close we get with just this small amount of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes an image and returns a label\n",
    "def purple_ratio_classifier(img):\n",
    "  keep_color = (186, 85, 211)\n",
    "  purple_ratio = HW06Utils.color_ratio(img, keep_color, 180)\n",
    "  if purple_ratio > 0.6:\n",
    "    return \"generated\"\n",
    "  else:\n",
    "    return \"original\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random classifier\n",
    "\n",
    "We're also gonna create a random classifier to use as a baseline for comparisons later.\n",
    "\n",
    "The random classifier just guesses a label randomly. Our model should do better than random guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random classifier to use for comparisons\n",
    "def random_classifier(_):\n",
    "  # the choice() function selects a random element from a list\n",
    "  return choice([\"generated\",\"original\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. Run classification on `train` data\n",
    "\n",
    "Let's iterate through all the train files again, and this time instead of saving the purple ratio value and the filename in the list, we'll save our calculated label and the filename.\n",
    "\n",
    "```py\n",
    "purple_ratio_predictions = [\n",
    "  [label, filename],\n",
    "  [label, filename],\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "We'll also keep track of classifications made by the `random_classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to keep info about predictions\n",
    "purple_ratio_predictions_train = []\n",
    "\n",
    "# list to keep info about random predictions\n",
    "random_predictions_train = []\n",
    "\n",
    "# iterate through all of the filenames inside the train files list\n",
    "for fname in train_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath = path.join(TRAIN_PATH, fname)\n",
    "\n",
    "  # open the image from the file\n",
    "  mimg = open_image(fpath)\n",
    "\n",
    "  # get prediction using model defined above\n",
    "  prediction = purple_ratio_classifier(mimg)\n",
    "\n",
    "  # get prediction using random classifier defined above\n",
    "  random_prediction = random_classifier(mimg)\n",
    "\n",
    "  # store the prediction and filename\n",
    "  purple_ratio_predictions_train.append([ prediction, fname ])\n",
    "\n",
    "  # store the random prediction and filename\n",
    "  random_predictions_train.append([ random_prediction, fname ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(purple_ratio_predictions_train))\n",
    "\n",
    "# look at first couple of predictions just to check that our format is correct\n",
    "print(purple_ratio_predictions_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# list to keep info about predictions\n",
    "purple_ratio_predictions_test = []\n",
    "\n",
    "for fname in test_files:\n",
    "  # this gets us the full location path for the filename\n",
    "  fpath = path.join(TEST_PATH, fname)\n",
    "\n",
    "  # open the image from the file\n",
    "  mimg = open_image(fpath)\n",
    "\n",
    "  # get prediction using model defined above\n",
    "  prediction = purple_ratio_classifier(mimg)\n",
    "\n",
    "  # store the prediction and filename\n",
    "  purple_ratio_predictions_test.append([ prediction, fname ])\n",
    "\n",
    "# check that we processed all files. This should be as long as the train_files list\n",
    "print(len(purple_ratio_predictions_test))\n",
    "\n",
    "# look at first couple of predictions just to check that our format is correct\n",
    "print(purple_ratio_predictions_test[:3])\n",
    "\n",
    "#print(\"Purple Classifier\", HW06Utils.classification_accuracy(purple_ratio_predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (transparent origin images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to add lable\n",
    "def add_label(fname):\n",
    "    # Initialize the label\n",
    "    if 'gen' in fname:  # Check if 'gen' is in the filename\n",
    "        label = 1  # Assign 1 if 'gen' is found\n",
    "    else:\n",
    "        label = 0  # Assign 0 otherwise\n",
    "    return label  # Return the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def classification_accuracy(train_files, train_predictions):\n",
    "\n",
    "    # Ensure train_predictions is a DataFrame with exactly one column\n",
    "    if not isinstance(train_predictions, pd.DataFrame) or train_predictions.shape[1] != 1:\n",
    "        raise ValueError(\"train_predictions must be a DataFrame with a single column.\")\n",
    "    \n",
    "    # Extract predictions as a flat list/array\n",
    "    predictions = train_predictions.iloc[:, 0].tolist()\n",
    "\n",
    "    # Check if train_files and predictions have the same length\n",
    "    if len(train_files) != len(predictions):\n",
    "        raise ValueError(\"The length of train_files and train_predictions must match.\")\n",
    "\n",
    "    # Generate true labels from the filenames\n",
    "    true_labels = [1 if 'gen' in fname else 0 for fname in train_files]\n",
    "\n",
    "    # Compare predictions with true labels\n",
    "    correct_predictions = sum([pred == true for pred, true in zip(predictions, true_labels)])\n",
    "\n",
    "    # Calculate accuracy as a percentage\n",
    "    accuracy = (correct_predictions / len(train_files)) * 100\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group every 4 elements into sublists within the array\n",
    "def group_pixels(pixel_array, group_size=4):\n",
    "    grouped_pixels = np.array(pixel_array).reshape(-1, group_size)\n",
    "    return grouped_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split for dataframe\n",
    "def train_test_split(data, test_ratio=0.2, random_seed=None):\n",
    "\n",
    "    # Set the random seed for reproducibility (optional)\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Convert to a NumPy array for easier manipulation if it's a list\n",
    "    if isinstance(data, list):\n",
    "        data = np.array(data)\n",
    "\n",
    "    # Shuffle the indices of the data\n",
    "    indices = np.arange(len(data))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Compute the split point\n",
    "    split_point = int(len(data) * (1 - test_ratio))\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_indices = indices[:split_point]\n",
    "    test_indices = indices[split_point:]\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):  # For DataFrame input\n",
    "        train_data = data.iloc[train_indices]\n",
    "        test_data = data.iloc[test_indices]\n",
    "    else:  # For lists or NumPy arrays\n",
    "        train_data = data[train_indices]\n",
    "        test_data = data[test_indices]\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split_combined(data_combined, test_size=0.2):\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data_combined)\n",
    "    \n",
    "    # Calculate the split index\n",
    "    split_index = int(len(data_combined) * (1 - test_size))\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_data = data_combined[:split_index]\n",
    "    test_data = data_combined[split_index:]\n",
    "    \n",
    "    # Convert into dictionaries\n",
    "    train = {'pixels': [], 'labels': [], 'file_names': []}\n",
    "    test = {'pixels': [], 'labels': [], 'file_names': []}\n",
    "    \n",
    "    # Populate the train and test dictionaries\n",
    "    for pixels, label, file_name in train_data:\n",
    "        train['pixels'].append(pixels)\n",
    "        train['labels'].append(label)\n",
    "        train['file_names'].append(file_name)\n",
    "    \n",
    "    for pixels, label, file_name in test_data:\n",
    "        test['pixels'].append(pixels)\n",
    "        test['labels'].append(label)\n",
    "        test['file_names'].append(file_name)\n",
    "    \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template for black and white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = add_label(fname)\n",
    "  img = open_image(path.join(\"./data/images/pokemon_train\", fname))\n",
    "  pixel_data.append(img.pixels)\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = add_label(fname)\n",
    "  img = open_image(path.join(\"./data/images/pokemon_train\", fname))\n",
    " # Convert the pixel data to a NumPy array\n",
    "  pixel_array = np.array(img.pixels)\n",
    "    \n",
    "    # Flatten the NumPy array\n",
    "  flattened_pixels = pixel_array.flatten()\n",
    "    \n",
    "  pixel_data.append(flattened_pixels)\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Color Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group the pixel data for display\n",
    "image_0 = group_pixels(pixel_data[0], group_size=4)\n",
    "image_10 = group_pixels(pixel_data[10], group_size=4)\n",
    "\n",
    "# Display the grouped pixel data\n",
    "display(make_image(image_0, width=120))\n",
    "display(make_image(image_10, width=120))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Pixels into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(pixel_data)\n",
    "train_df[\"label\"] = label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixel_data = []\n",
    "\n",
    "# Flatten pixel data for each image\n",
    "for fname in test_files:\n",
    "    img = open_image(path.join(\"./data/images/pokemon_test\", fname))\n",
    "    # Flatten the image pixels into a 1D array\n",
    "    flattened_pixels = np.array(img.pixels).flatten()\n",
    "    test_pixel_data.append(flattened_pixels)\n",
    "\n",
    "# Load into DataFrame\n",
    "test_df = pd.DataFrame(test_pixel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split input and output features\n",
    "NUM_FEATURES = 5\n",
    "chosen_columns = train_df.columns[:NUM_FEATURES]\n",
    "train_features = train_df[chosen_columns]\n",
    "\n",
    "out_features = train_df[\"label\"]\n",
    "\n",
    "# also separate test dataset features\n",
    "test_features = test_df[chosen_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a brand new classifier\n",
    "image_model = RandomForestClassifier()\n",
    "# TODO: fit the model\n",
    "image_model.fit(train_features, out_features)\n",
    "# TODO: run predictions\n",
    "train_predictions = image_model.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_accuracy(train_files, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run predictions on test data\n",
    "test_predictions = image_model.predict(test_features)\n",
    "# TODO: measure classification accuracy\n",
    "classification_accuracy(test_files, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA from HW10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_GEN_PATH = \"data/images/pokemon_generated\"\n",
    "\n",
    "# Get all of the filenames that end in \"jpg\" inside the test directory\n",
    "train_gen_files = [f for f in listdir(TRAIN_GEN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the data\n",
    "pixel_data = []\n",
    "label_data = []\n",
    "file_names = []\n",
    "\n",
    "for fname in train_gen_files:\n",
    "    # Get the label for the image\n",
    "    label = add_label(fname)\n",
    "    \n",
    "    # Load the image\n",
    "    img = open_image(path.join(\"./data/images/pokemon_generated\", fname))\n",
    "    \n",
    "    # Convert the pixel data to a NumPy array and flatten it\n",
    "    pixel_array = np.array(img.pixels).flatten()\n",
    "    \n",
    "    # Append the data to the respective lists\n",
    "    pixel_data.append(pixel_array.tolist())  # Convert flattened NumPy array to list\n",
    "    label_data.append(label)\n",
    "    file_names.append(fname)\n",
    "\n",
    "# Create the DataFrame with three columns\n",
    "\n",
    "train_gen_df = pd.DataFrame({\n",
    "    \"pixels\": pixel_data,\n",
    "    \"label\": label_data,\n",
    "    \"fname\": file_names\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(train_gen_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pixel_data, label_data, and file_names into a single list\n",
    "train_gen = list(zip(pixel_data, label_data, file_names))\n",
    "\n",
    "# Example: Display the first combined item\n",
    "print(train_gen[0])  # Output: (pixels_list, label, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split_combined(train_gen,0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pca = PCA(n_components=8)\n",
    "train_df = face_pca.fit_transform(train[\"pixels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"explained variance:\", face_pca.explained_variance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this label to your label to see how\n",
    "#       your images are being encoded\n",
    "awesome_label = \"1\"\n",
    "\n",
    "\n",
    "# this filters the DataFrame by our label\n",
    "awesome_df = train_df\n",
    "\n",
    "# reconstruct all images\n",
    "pca_pixels = face_pca.inverse_transform(awesome_df)\n",
    "\n",
    "# associate the original indexes with the reconstructed pca pixels\n",
    "idx_pca = zip(awesome_df.index, pca_pixels.values)\n",
    "\n",
    "# iterate through indexes and pca pixels\n",
    "for img_idx, img_pca in list(idx_pca)[:5]:\n",
    "  print(\"label:\", awesome_label,\n",
    "        \"\\nfrom:\", train[\"file_names\"][img_idx])\n",
    "  # Group the pixel data for display\n",
    "  image_0 = group_pixels(train[\"pixels\"][img_idx], group_size=4)\n",
    "  image_10 = group_pixels(img_pca, group_size=4)\n",
    "\n",
    "# Display the grouped pixel data\n",
    "  display(make_image(image_0, width=120))\n",
    "  display(make_image(image_10, width=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ORI_PATH = \"data/images/pokemon_origin\"\n",
    "\n",
    "# Get all of the filenames that end in \"jpg\" inside the test directory\n",
    "train_ori_files = [f for f in listdir(TRAIN_ORI_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the data\n",
    "pixel_data = []\n",
    "label_data = []\n",
    "file_names = []\n",
    "\n",
    "for fname in train_ori_files:\n",
    "    # Get the label for the image\n",
    "    label = add_label(fname)\n",
    "    \n",
    "    # Load the image\n",
    "    img = open_image(path.join(\"./data/images/pokemon_origin\", fname))\n",
    "    \n",
    "    # Convert the pixel data to a NumPy array and flatten it\n",
    "    pixel_array = np.array(img.pixels).flatten()\n",
    "    \n",
    "    # Append the data to the respective lists\n",
    "    pixel_data.append(pixel_array.tolist())  # Convert flattened NumPy array to list\n",
    "    label_data.append(label)\n",
    "    file_names.append(fname)\n",
    "\n",
    "# Create the DataFrame with three columns\n",
    "\n",
    "train_ori_df = pd.DataFrame({\n",
    "    \"pixels\": pixel_data,\n",
    "    \"label\": label_data,\n",
    "    \"fname\": file_names\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(train_ori_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pixel_data, label_data, and file_names into a single list\n",
    "train_ori = list(zip(pixel_data, label_data, file_names))\n",
    "\n",
    "# Example: Display the first combined item\n",
    "print(train_ori[0])  # Output: (pixels_list, label, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split_combined(train_ori,0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pca = PCA(n_components=8)\n",
    "train_df = face_pca.fit_transform(train[\"pixels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"explained variance:\", face_pca.explained_variance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this label to your label to see how\n",
    "#       your images are being encoded\n",
    "awesome_label = \"0\"\n",
    "\n",
    "\n",
    "# this filters the DataFrame by our label\n",
    "awesome_df = train_df\n",
    "\n",
    "# reconstruct all images\n",
    "pca_pixels = face_pca.inverse_transform(awesome_df)\n",
    "\n",
    "# associate the original indexes with the reconstructed pca pixels\n",
    "idx_pca = zip(awesome_df.index, pca_pixels.values)\n",
    "\n",
    "# iterate through indexes and pca pixels\n",
    "for img_idx, img_pca in list(idx_pca)[:5]:\n",
    "  print(\"label:\", awesome_label,\n",
    "        \"\\nfrom:\", train[\"file_names\"][img_idx])\n",
    "  # Group the pixel data for display\n",
    "  image_0 = group_pixels(train[\"pixels\"][img_idx], group_size=4)\n",
    "  image_10 = group_pixels(img_pca, group_size=4)\n",
    "\n",
    "# Display the grouped pixel data\n",
    "  display(make_image(image_0, width=120))\n",
    "  display(make_image(image_10, width=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first attempted to manually classify the generated images and the original images based on the use of the purple pixel color and the result works really well. Based on this observation, I decided to further test the performance of a pre-built model, such as a Random Forest classifier, to see how it performs. One possible reason why the Random Forest classifier worked so well is that the original images are PNG files without a background, whereas the generated images include a background.\n",
    "\n",
    "Another reason could be the differences in how the color purple is used in the generated and original images, as indicated by a subsequent PCA analysis on both sets of images. For the PCA on the generated images, those with colors closer to purple tend to produce blurrier results, revealing additional layers with purple tones in the background. In contrast, for images like Pikachu that contain fewer red or purple tones, the results appear clearer compared to those with more red or purple tones.\n",
    "\n",
    "For the original images, PokÃ©mon primarily constructed with red tones remain clear even after applying PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification with Background for Both Generated and Original Pokemon Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Show Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare location of train files\n",
    "TRAIN_PATH = \"data/images/pokemon_train_white\"\n",
    "\n",
    "# List comprehension for getting all of the filenames that end in \"png\" inside the train directory\n",
    "train_files = [f for f in listdir(TRAIN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = add_label(fname)\n",
    "  img = open_image(path.join(\"./data/images/pokemon_train_white\", fname))\n",
    " # Convert the pixel data to a NumPy array\n",
    "  pixel_array = np.array(img.pixels)\n",
    "    \n",
    "    # Flatten the NumPy array\n",
    "  flattened_pixels = pixel_array.flatten()\n",
    "    \n",
    "  pixel_data.append(flattened_pixels)\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group the pixel data for display\n",
    "image_0 = group_pixels(pixel_data[0], group_size=4)\n",
    "image_10 = group_pixels(pixel_data[10], group_size=4)\n",
    "\n",
    "# Display the grouped pixel data\n",
    "display(make_image(image_0, width=120))\n",
    "display(make_image(image_10, width=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Pixels into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(pixel_data)\n",
    "train_df[\"label\"] = label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>57591</th>\n",
       "      <th>57592</th>\n",
       "      <th>57593</th>\n",
       "      <th>57594</th>\n",
       "      <th>57595</th>\n",
       "      <th>57596</th>\n",
       "      <th>57597</th>\n",
       "      <th>57598</th>\n",
       "      <th>57599</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>255</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>255</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>255</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>255</td>\n",
       "      <td>210</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>255</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>212</td>\n",
       "      <td>255</td>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>212</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  57591  57592  57593  \\\n",
       "0  173  173  173  255  172  172  172  255  171  171  ...    255    172    172   \n",
       "1  255  255  255  255  255  255  255  255  255  255  ...    255    255    255   \n",
       "2  255  255  255  255  255  255  255  255  255  255  ...    255    255    255   \n",
       "3  255  255  255  255  255  255  255  255  255  255  ...    255    255    255   \n",
       "4  211  213  214  255  210  212  213  255  210  211  ...    255    209    210   \n",
       "\n",
       "   57594  57595  57596  57597  57598  57599  label  \n",
       "0    172    255    171    171    171    255      1  \n",
       "1    255    255    255    255    255    255      0  \n",
       "2    255    255    255    255    255    255      0  \n",
       "3    255    255    255    255    255    255      0  \n",
       "4    212    255    209    210    212    255      1  \n",
       "\n",
       "[5 rows x 57601 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare location of test files\n",
    "TRAIN_PATH = \"data/images/pokemon_test_white\"\n",
    "\n",
    "# List comprehension for getting all of the filenames that end in \"png\" inside the train directory\n",
    "test_files = [f for f in listdir(TRAIN_PATH) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixel_data = []\n",
    "\n",
    "# Flatten pixel data for each image\n",
    "for fname in test_files:\n",
    "    img = open_image(path.join(\"./data/images/pokemon_test_white\", fname))\n",
    "    # Flatten the image pixels into a 1D array\n",
    "    flattened_pixels = np.array(img.pixels).flatten()\n",
    "    test_pixel_data.append(flattened_pixels)\n",
    "\n",
    "# Load into DataFrame\n",
    "test_df = pd.DataFrame(test_pixel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split input and output features\n",
    "NUM_FEATURES = 5\n",
    "chosen_columns = train_df.columns[:NUM_FEATURES]\n",
    "train_features = train_df[chosen_columns]\n",
    "\n",
    "out_features = train_df[\"label\"]\n",
    "\n",
    "# also separate test dataset features\n",
    "test_features = test_df[chosen_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a brand new classifier\n",
    "image_model = RandomForestClassifier()\n",
    "# TODO: fit the model\n",
    "image_model.fit(train_features, out_features)\n",
    "# TODO: run predictions\n",
    "train_predictions = image_model.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_accuracy(train_files, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: run predictions on test data\n",
    "test_predictions = image_model.predict(test_features)\n",
    "# TODO: measure classification accuracy\n",
    "classification_accuracy(test_files, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still works well when the original image change from the transparent background into the white one as the generated files. Thus, I do not think the background is the reason that the classifier works so well. In contrast, according to the result of pca and the manual classifier I remain to the assumption that this is because the original images and the generated images use the color purple differently. The following session, I would use HW12 as a template to try the tensor to see if that works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
